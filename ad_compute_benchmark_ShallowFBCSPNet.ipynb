{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import scipy\n",
    "import scipy.signal\n",
    "import scipy.io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from joblib.parallel import Parallel, delayed\n",
    "\n",
    "import shutil\n",
    "\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "# from skorch.callbacks import LRScheduler, BatchScoring\n",
    "# from skorch.helper import SliceDataset\n",
    "\n",
    "# from braindecode.datasets import WindowsDataset, BaseConcatDataset\n",
    "# from braindecode.util import set_random_seeds\n",
    "# from braindecode.models import ShallowFBCSPNet, Deep4Net\n",
    "# from braindecode.models.util import to_dense_prediction_model\n",
    "# from braindecode.models.modules import Expression\n",
    "# from braindecode import EEGRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove all logs \n",
    "\n",
    "# path = os.path.abspath(\"logs\")\n",
    "# print(path)\n",
    "# if os.path.exists(path):\n",
    "#     shutil.rmtree(path)\n",
    "# os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data + create dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/vol/aimspace/users/dena/Documents/mae/data/lemon\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw_test = torch.load(os.path.join(folder_path, \"data_raw_test.pt\"))\n",
    "data_raw_train = torch.load(os.path.join(folder_path, \"data_raw_train.pt\"))\n",
    "data_raw_val = torch.load(os.path.join(folder_path, \"data_raw_val.pt\"))\n",
    "\n",
    "labels_raw_test = torch.load(os.path.join(folder_path, \"labels_raw_test.pt\"))\n",
    "labels_raw_train = torch.load(os.path.join(folder_path, \"labels_raw_train.pt\"))\n",
    "labels_raw_val = torch.load(os.path.join(folder_path, \"labels_raw_val.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOVEL ATTEMPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_params = {\n",
    "    \"num_epochs\": 100, \n",
    "    \"batch_size\": 64, \n",
    "    \"hidden_size1\": 4096, # 512, \n",
    "    \"hidden_size2\": 128, \n",
    "    \"lr\": 0.002, \n",
    "\n",
    "    \"number_samples\": 4  # either None for all samples or int  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val\n",
      "torch.Size([32, 61, 2000])\n",
      "Train\n",
      "torch.Size([150, 61, 2000])\n",
      "Test\n",
      "torch.Size([32, 61, 2000])\n"
     ]
    }
   ],
   "source": [
    "time_steps = 2000\n",
    "\n",
    "def split_dataset(raw_dataset, labels_raw, time_steps): \n",
    "    num_chunks_per_sample = raw_dataset.shape[-1] // time_steps  # This calculates to 15\n",
    "    \n",
    "    # Split the tensor along the last dimension; discard last chunk if it does not have the full time_steps\n",
    "    chunks_data = torch.split(raw_dataset, time_steps, dim=2) #, dim=-1)\n",
    "    print(chunks_data[0].shape)\n",
    "    stacked_tensor = torch.stack(chunks_data, dim=1)\n",
    "    \n",
    "    return stacked_tensor\n",
    "\n",
    "print(\"Val\")\n",
    "data_val = split_dataset(data_raw_val, labels_raw_val, time_steps)\n",
    "print(\"Train\")\n",
    "data_train = split_dataset(data_raw_train, labels_raw_train, time_steps)\n",
    "print(\"Test\")\n",
    "data_test = split_dataset(data_raw_test, labels_raw_test, time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, X, y, number_samples=None):\n",
    "        if number_samples: \n",
    "            indices = np.random.choice(range(len(X[0])), number_samples, replace=False)\n",
    "            self.X = X[indices]\n",
    "            self.y = y[indices]\n",
    "        else: \n",
    "            self.X = X\n",
    "            self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        participant_trials = self.X[idx]\n",
    "        label = self.y[idx]\n",
    "        return participant_trials, label\n",
    "\n",
    "\n",
    "train_dataset = EEGDataset(data_train, labels_raw_train, h_params[\"number_samples\"]) #, number_samples=32) #!!! CHANGE AGAIN!! \n",
    "val_dataset = EEGDataset(data_val, labels_raw_val, h_params[\"number_samples\"]) #, number_samples=32) #!!! CHANGE AGAIN!! \n",
    "test_dataset = EEGDataset(data_test, labels_raw_test, h_params[\"number_samples\"]) #, number_samples=32) #!!! CHANGE AGAIN!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=122000, out_features=4096, bias=True)\n",
      "  (maxpool1): MaxPool2d(kernel_size=(1, 3), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc2): Linear(in_features=4096, out_features=128, bias=True)\n",
      "  (fc2_1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (activation): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model = InspiredEEGNet(n_channels=15, n_classes=1, input_time_length=2000)\n",
    "model = SimpleNN()\n",
    "print(model)\n",
    "# 1830000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "    '''\n",
    "    Resets model weights to avoid weight leakage across folds during cross-validation.\n",
    "    Applies to layers with explicit weight parameters (e.g., Conv2d, Linear).\n",
    "    '''\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            init.zeros_(m.bias)\n",
    "    # Add other layer types here if necessary. For example:\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        init.constant_(m.weight, 1)\n",
    "        init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Create Dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=h_params[\"batch_size\"], shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=h_params[\"batch_size\"], shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=h_params[\"batch_size\"], shuffle=False, num_workers=4)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# model = SimpleNN()\n",
    "criterion = nn.BCEloss() #MSELoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=h_params[\"lr\"]) \n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cross_validation(data, num_folds, hyperparameters, unique_identifier):\n",
    "\n",
    "    rate_of_updates = 5 \n",
    "    \n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(data)):\n",
    "        writer_name = f'logs/{unique_identifier}-fold_{fold}'\n",
    "        writer = SummaryWriter(log_dir=writer_name)\n",
    "\n",
    "        # Log hyperparameters\n",
    "        h_params_text = \"Hyperparameters:  \"\n",
    "        for key, value in hyperparameters.items():\n",
    "            h_params_text += f\"{key}: {value}, \"\n",
    "        writer.add_text(tag='EEG_shallowFBCSPNet', text_string=h_params_text)\n",
    "\n",
    "        # writer.add_hparams(hparam_dict=hyperparameters, )\n",
    "\n",
    "        train_subset = torch.utils.data.Subset(data, train_idx)\n",
    "        val_subset = torch.utils.data.Subset(data, val_idx)\n",
    "\n",
    "        # Create DataLoaders for the current fold\n",
    "        train_loader = DataLoader(train_subset, batch_size=h_params[\"batch_size\"], shuffle=True) #, num_workers=4)\n",
    "        val_loader = DataLoader(val_subset, batch_size=h_params[\"batch_size\"], shuffle=False) #, num_workers=4)\n",
    "\n",
    "        # Reset model to initial state\n",
    "        # model = model.to(device)\n",
    "        model.apply(reset_weights)\n",
    "        # (Re)initialize the optimizer if needed since model weights are reset\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=h_params[\"lr\"])\n",
    "\n",
    "        for epoch in range(hyperparameters[\"num_epochs\"]): \n",
    "            model.train()\n",
    "            train_running_loss = 0.0\n",
    "            \n",
    "            for i, (X,y) in enumerate(train_loader):\n",
    "            # Ensure data is on the correct device\n",
    "\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                outputs = model(X)\n",
    "                loss = criterion(outputs, y)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_running_loss += np.sqrt(loss.item()) \n",
    "                writer.add_scalar('Loss_in_years/train', train_running_loss, epoch * len(train_loader) + i)\n",
    "\n",
    "            avg_train_loss = train_running_loss/len(train_loader)\n",
    "\n",
    "            # if epoch % rate_of_updates == 0: \n",
    "            #     print(f'Fold {fold+1}, Epoch [{epoch+1}/{h_params[\"num_epochs\"]}], Train Loss: {avg_train_loss:.4f}')\n",
    "            \n",
    "            print(f'Fold {fold+1}, Epoch [{epoch+1}/{h_params[\"num_epochs\"]}], Train Loss: {avg_train_loss:.4f}')\n",
    "        \n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            val_running_loss = 0.0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for i, (X,y) in enumerate(val_loader):\n",
    "                    X, y = X.to(device), y.to(device)\n",
    "                    \n",
    "                    outputs = model(X)\n",
    "                    val_loss = criterion(outputs, y)\n",
    "                    \n",
    "                    val_running_loss += np.sqrt(val_loss.item())\n",
    "\n",
    "                    # avg_val_loss = val_running_loss / len(val_loader)\n",
    "                    writer.add_scalar('Loss_in_years/val', np.sqrt(val_loss.item()), epoch * len(val_loader) + i)\n",
    "\n",
    "            avg_val_loss = val_running_loss / len(val_loader)\n",
    "\n",
    "        writer.add_hparams(hparam_dict=hyperparameters, metric_dict={\"Loss_in_years/train\": avg_train_loss, \"Loss_in_years/val\": avg_val_loss})\n",
    "\n",
    "            \n",
    "        print(f'Fold {fold+1}, Epoch [{epoch+1}/{h_params[\"num_epochs\"]}], Validation Loss: {avg_val_loss:.4f}')\n",
    "        # writer.add_scalar('Loss_in_years/val', avg_val_loss, epoch * len(val_loader) + i)\n",
    "\n",
    "        # Log fold results\n",
    "        fold_results.append(avg_val_loss)\n",
    "\n",
    "        # writer.add_hparams(hparam_dict=hyperparameters, metric_dict={\"Loss_in_years/train\": train_running_loss, \"Loss_in_years/val\": val_running_loss})\n",
    "\n",
    "\n",
    "    # Evtl hier logs für epochs? \n",
    "\n",
    "    # After all folds\n",
    "    print(f'Individual Validation Losses for all folds: {fold_results}')\n",
    "    print(f'Average Validation Loss across all folds: {np.mean(fold_results):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cross_validation_on_the_simple_fcn(data, num_folds, hyperparameters, unique_identifier):\n",
    "\n",
    "    rate_of_updates = 5 \n",
    "    \n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(data)):\n",
    "        writer_name = f'logs/{unique_identifier}-fold_{fold}'\n",
    "        writer = SummaryWriter(log_dir=writer_name)\n",
    "\n",
    "        # Log hyperparameters\n",
    "        h_params_text = \"Hyperparameters:  \"\n",
    "        for key, value in hyperparameters.items():\n",
    "            h_params_text += f\"{key}: {value}, \"\n",
    "        writer.add_text(tag='EEG_shallowFBCSPNet', text_string=h_params_text)\n",
    "\n",
    "        # writer.add_hparams(hparam_dict=hyperparameters, )\n",
    "\n",
    "        train_subset = torch.utils.data.Subset(data, train_idx)\n",
    "        val_subset = torch.utils.data.Subset(data, val_idx)\n",
    "\n",
    "        # Create DataLoaders for the current fold\n",
    "        train_loader = DataLoader(train_subset, batch_size=h_params[\"batch_size\"], shuffle=True) #, num_workers=4)\n",
    "        val_loader = DataLoader(val_subset, batch_size=h_params[\"batch_size\"], shuffle=False) #, num_workers=4)\n",
    "\n",
    "        # Reset model to initial state\n",
    "        # model = model.to(device)\n",
    "        model.apply(reset_weights)\n",
    "        # (Re)initialize the optimizer if needed since model weights are reset\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=h_params[\"lr\"])\n",
    "\n",
    "        for epoch in range(hyperparameters[\"num_epochs\"]): \n",
    "            model.train()\n",
    "            train_running_loss = 0.0\n",
    "            \n",
    "            for i, (X_batch,y_batch) in enumerate(train_loader): \n",
    "                for X in X_batch.squeeze(0): #, y_batch): #zip(X_batch[:,i,:,:],y_batch[:,i,:,:]): \n",
    "            # Ensure data is on the correct device\n",
    "                    print(X.shape)\n",
    "\n",
    "                    X, y = X.unsqueeze(0).to(device), y_batch.to(device)\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    outputs = model(X)\n",
    "                    loss = criterion(outputs, y)\n",
    "                    \n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                train_running_loss += np.sqrt(loss.item()) \n",
    "                writer.add_scalar('Loss_in_years/train', train_running_loss, epoch * len(train_loader) + i)\n",
    "\n",
    "            avg_train_loss = train_running_loss/len(train_loader)\n",
    "\n",
    "            # if epoch % rate_of_updates == 0: \n",
    "            #     print(f'Fold {fold+1}, Epoch [{epoch+1}/{h_params[\"num_epochs\"]}], Train Loss: {avg_train_loss:.4f}')\n",
    "            \n",
    "            print(f'Fold {fold+1}, Epoch [{epoch+1}/{h_params[\"num_epochs\"]}], Train Loss: {avg_train_loss:.4f}')\n",
    "        \n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            val_running_loss = 0.0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for i, (X_batch,y_batch) in enumerate(val_loader):\n",
    "                    \n",
    "                    for X in X_batch.squeeze(0): #X, y in zip(X_batch[:,i,:,:],y_batch[:,i,:,:]): \n",
    "                        X, y = X.unsqueeze(0).to(device), y_batch.to(device)\n",
    "                        # X, y = X.to(device), y.to(device)\n",
    "                        \n",
    "                        outputs = model(X)\n",
    "                        val_loss = criterion(outputs, y)\n",
    "                        \n",
    "                        val_running_loss += np.sqrt(val_loss.item())\n",
    "\n",
    "                        # avg_val_loss = val_running_loss / len(val_loader)\n",
    "                        writer.add_scalar('Loss_in_years/val', np.sqrt(val_loss.item()), epoch * len(val_loader) + i)\n",
    "\n",
    "            avg_val_loss = val_running_loss / len(val_loader)\n",
    "\n",
    "        writer.add_hparams(hparam_dict=hyperparameters, metric_dict={\"Loss_in_years/train\": avg_train_loss, \"Loss_in_years/val\": avg_val_loss})\n",
    "\n",
    "            \n",
    "        print(f'Fold {fold+1}, Epoch [{epoch+1}/{h_params[\"num_epochs\"]}], Validation Loss: {avg_val_loss:.4f}')\n",
    "        # writer.add_scalar('Loss_in_years/val', avg_val_loss, epoch * len(val_loader) + i)\n",
    "\n",
    "        # Log fold results\n",
    "        fold_results.append(avg_val_loss)\n",
    "\n",
    "        # writer.add_hparams(hparam_dict=hyperparameters, metric_dict={\"Loss_in_years/train\": train_running_loss, \"Loss_in_years/val\": val_running_loss})\n",
    "\n",
    "\n",
    "    # Evtl hier logs für epochs? \n",
    "\n",
    "    # After all folds\n",
    "    print(f'Individual Validation Losses for all folds: {fold_results}')\n",
    "    print(f'Average Validation Loss across all folds: {np.mean(fold_results):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cross_validation2(X_data,y_data, num_folds, hyperparameters, unique_identifier):\n",
    "\n",
    "    rate_of_updates = 5 \n",
    "    \n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_data)):\n",
    "\n",
    "        # Tensorboard\n",
    "        writer_name = f'logs/{unique_identifier}-fold_{fold}'\n",
    "        writer = SummaryWriter(log_dir=writer_name)\n",
    "\n",
    "        # Tensorboard: Log hyperparameters\n",
    "        h_params_text = \"Hyperparameters:  \"\n",
    "        for key, value in hyperparameters.items():\n",
    "            h_params_text += f\"{key}: {value}, \"\n",
    "        writer.add_text(tag='EEG_shallowFBCSPNet', text_string=h_params_text)\n",
    "\n",
    "        # writer.add_hparams(hparam_dict=hyperparameters, )\n",
    "\n",
    "        train_subset = torch.utils.data.Subset(X_data, train_idx)\n",
    "        val_subset = torch.utils.data.Subset(X_data, val_idx)\n",
    "\n",
    "        # Create DataLoaders for the current fold\n",
    "        train_loader = DataLoader(train_subset, batch_size=h_params[\"batch_size\"], shuffle=True) #, num_workers=4)\n",
    "        val_loader = DataLoader(val_subset, batch_size=h_params[\"batch_size\"], shuffle=False) #, num_workers=4)\n",
    "\n",
    "        # Reset model to initial state\n",
    "        # model = model.to(device)\n",
    "        model.apply(reset_weights)\n",
    "        # (Re)initialize the optimizer if needed since model weights are reset\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=h_params[\"lr\"])\n",
    "\n",
    "        for epoch in range(hyperparameters[\"num_epochs\"]): \n",
    "            model.train()\n",
    "            train_running_loss = 0.0\n",
    "            \n",
    "            for i, (X,y) in enumerate(train_loader):\n",
    "            # Ensure data is on the correct device\n",
    "\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                outputs = model(X)\n",
    "                loss = criterion(outputs, y)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_running_loss += np.sqrt(loss.item()) \n",
    "                writer.add_scalar('Loss_in_years/train', train_running_loss, epoch * len(train_loader) + i)\n",
    "\n",
    "            avg_train_loss = train_running_loss/len(train_loader)\n",
    "\n",
    "            # if epoch % rate_of_updates == 0: \n",
    "            #     print(f'Fold {fold+1}, Epoch [{epoch+1}/{h_params[\"num_epochs\"]}], Train Loss: {avg_train_loss:.4f}')\n",
    "            \n",
    "            print(f'Fold {fold+1}, Epoch [{epoch+1}/{h_params[\"num_epochs\"]}], Train Loss: {avg_train_loss:.4f}')\n",
    "        \n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            val_running_loss = 0.0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for i, (X,y) in enumerate(val_loader):\n",
    "                    X, y = X.to(device), y.to(device)\n",
    "                    \n",
    "                    outputs = model(X)\n",
    "                    val_loss = criterion(outputs, y)\n",
    "                    \n",
    "                    val_running_loss += np.sqrt(val_loss.item())\n",
    "\n",
    "                    # avg_val_loss = val_running_loss / len(val_loader)\n",
    "                    writer.add_scalar('Loss_in_years/val', np.sqrt(val_loss.item()), epoch * len(val_loader) + i)\n",
    "\n",
    "            avg_val_loss = val_running_loss / len(val_loader)\n",
    "\n",
    "        writer.add_hparams(hparam_dict=hyperparameters, metric_dict={\"Loss_in_years/train\": avg_train_loss, \"Loss_in_years/val\": avg_val_loss})\n",
    "\n",
    "            \n",
    "        print(f'Fold {fold+1}, Epoch [{epoch+1}/{h_params[\"num_epochs\"]}], Validation Loss: {avg_val_loss:.4f}')\n",
    "        # writer.add_scalar('Loss_in_years/val', avg_val_loss, epoch * len(val_loader) + i)\n",
    "\n",
    "        # Log fold results\n",
    "        fold_results.append(avg_val_loss)\n",
    "\n",
    "        # writer.add_hparams(hparam_dict=hyperparameters, metric_dict={\"Loss_in_years/train\": train_running_loss, \"Loss_in_years/val\": val_running_loss})\n",
    "\n",
    "\n",
    "    # Evtl hier logs für epochs? \n",
    "\n",
    "    # After all folds\n",
    "    print(f'Individual Validation Losses for all folds: {fold_results}')\n",
    "    print(f'Average Validation Loss across all folds: {np.mean(fold_results):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from skorch import NeuralNetClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mX\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 61, 2000])\n",
      "torch.Size([15, 61, 2000])\n",
      "torch.Size([150, 61, 2000])\n",
      "torch.Size([150, 1])\n"
     ]
    }
   ],
   "source": [
    "print(data_train[0].shape)\n",
    "print(data_train[1].shape)\n",
    "\n",
    "print(data_raw_train[:,:,:2000].shape)\n",
    "print(labels_raw_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1     \u001b[36m1982.4697\u001b[0m    \u001b[32m52382.6602\u001b[0m  0.0930\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "      2    50935.3867     \u001b[32m5688.5630\u001b[0m  0.0859\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "      3     6248.6836     \u001b[32m3691.7283\u001b[0m  0.0867\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "      4     4150.0469     \u001b[32m2430.0427\u001b[0m  0.0864\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "      5     2806.9199     \u001b[32m1635.5948\u001b[0m  0.0854\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "      6     \u001b[36m1947.3188\u001b[0m     \u001b[32m1137.5726\u001b[0m  0.0855\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "      7     \u001b[36m1397.1741\u001b[0m      \u001b[32m827.1780\u001b[0m  0.0862\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "      8     \u001b[36m1045.0814\u001b[0m      \u001b[32m635.1971\u001b[0m  0.0844\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "      9      \u001b[36m819.7421\u001b[0m      \u001b[32m517.6668\u001b[0m  0.0863\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     10      \u001b[36m675.5250\u001b[0m      \u001b[32m446.7171\u001b[0m  0.0856\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     11      \u001b[36m583.2259\u001b[0m      \u001b[32m404.7254\u001b[0m  0.0855\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     12      \u001b[36m524.1546\u001b[0m      \u001b[32m380.5833\u001b[0m  0.0854\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     13      \u001b[36m486.3489\u001b[0m      \u001b[32m367.3186\u001b[0m  0.0855\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     14      \u001b[36m462.1534\u001b[0m      \u001b[32m360.5782\u001b[0m  0.0853\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     15      \u001b[36m446.6681\u001b[0m      \u001b[32m357.6634\u001b[0m  0.0855\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     16      \u001b[36m436.7576\u001b[0m      \u001b[32m356.9173\u001b[0m  0.0854\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     17      \u001b[36m430.4149\u001b[0m      357.3352  0.0862\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     18      \u001b[36m426.3556\u001b[0m      358.3191  0.0852\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     19      \u001b[36m423.7575\u001b[0m      359.5219  0.0851\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     20      \u001b[36m422.0948\u001b[0m      360.7501  0.0853\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     21      \u001b[36m421.0307\u001b[0m      361.9030  0.0862\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     22      \u001b[36m420.3497\u001b[0m      362.9342  0.0854\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     23      \u001b[36m419.9138\u001b[0m      363.8289  0.0853\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     24      \u001b[36m419.6349\u001b[0m      364.5894  0.0855\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     25      \u001b[36m419.4563\u001b[0m      365.2263  0.0862\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     26      \u001b[36m419.3420\u001b[0m      365.7541  0.0859\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     27      \u001b[36m419.2689\u001b[0m      366.1880  0.0851\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     28      \u001b[36m419.2221\u001b[0m      366.5427  0.0842\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     29      \u001b[36m419.1922\u001b[0m      366.8312  0.0833\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     30      \u001b[36m419.1730\u001b[0m      367.0651  0.0828\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     31      \u001b[36m419.1607\u001b[0m      367.2541  0.0852\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     32      \u001b[36m419.1529\u001b[0m      367.4066  0.0830\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     33      \u001b[36m419.1478\u001b[0m      367.5294  0.0825\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     34      \u001b[36m419.1446\u001b[0m      367.6281  0.0823\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     35      \u001b[36m419.1426\u001b[0m      367.7075  0.0825\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     36      \u001b[36m419.1412\u001b[0m      367.7712  0.0831\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     37      \u001b[36m419.1404\u001b[0m      367.8223  0.0827\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     38      \u001b[36m419.1399\u001b[0m      367.8632  0.0830\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     39      \u001b[36m419.1395\u001b[0m      367.8961  0.0832\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     40      \u001b[36m419.1393\u001b[0m      367.9224  0.0828\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     41      \u001b[36m419.1392\u001b[0m      367.9434  0.0831\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     42      \u001b[36m419.1391\u001b[0m      367.9602  0.0832\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     43      \u001b[36m419.1390\u001b[0m      367.9737  0.0830\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     44      \u001b[36m419.1390\u001b[0m      367.9845  0.0829\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     45      \u001b[36m419.1389\u001b[0m      367.9932  0.0826\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     46      419.1389      368.0001  0.0824\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     47      \u001b[36m419.1389\u001b[0m      368.0056  0.0826\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     48      \u001b[36m419.1389\u001b[0m      368.0100  0.0827\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     49      419.1389      368.0136  0.0829\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     50      419.1389      368.0164  0.0845\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     51      419.1389      368.0187  0.0822\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     52      419.1389      368.0205  0.0821\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     53      419.1389      368.0220  0.0824\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     54      419.1389      368.0231  0.0826\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     55      419.1389      368.0241  0.0819\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     56      419.1389      368.0248  0.0820\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     57      419.1389      368.0254  0.0824\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     58      419.1389      368.0259  0.0815\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     59      419.1389      368.0262  0.0824\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     60      419.1389      368.0266  0.0822\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     61      419.1389      368.0269  0.0823\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     62      419.1389      368.0270  0.0823\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     63      419.1389      368.0272  0.0820\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     64      419.1389      368.0273  0.0819\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     65      419.1389      368.0274  0.0819\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     66      419.1389      368.0275  0.0817\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     67      419.1389      368.0275  0.0819\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     68      419.1389      368.0276  0.0821\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     69      419.1389      368.0276  0.0820\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     70      419.1389      368.0276  0.0823\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     71      419.1389      368.0277  0.0821\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     72      419.1389      368.0277  0.0819\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     73      419.1389      368.0277  0.0817\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     74      419.1389      368.0277  0.0819\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     75      419.1389      368.0277  0.0818\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     76      419.1389      368.0277  0.0825\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     77      419.1389      368.0277  0.0820\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     78      419.1389      368.0277  0.0820\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     79      419.1389      368.0277  0.0818\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     80      419.1389      368.0277  0.0819\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     81      419.1389      368.0277  0.0818\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     82      419.1389      368.0277  0.0820\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     83      419.1389      368.0277  0.0819\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     84      419.1389      368.0277  0.0818\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     85      419.1389      368.0277  0.0815\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     86      419.1389      368.0277  0.0820\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     87      419.1389      368.0277  0.0820\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     88      419.1389      368.0277  0.0821\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     89      419.1389      368.0277  0.0817\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     90      419.1389      368.0277  0.0820\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     91      419.1389      368.0277  0.0819\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     92      419.1389      368.0277  0.0829\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     93      419.1389      368.0277  0.0819\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     94      419.1389      368.0277  0.0820\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     95      419.1389      368.0277  0.0819\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     96      419.1389      368.0277  0.0823\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     97      419.1389      368.0277  0.0828\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     98      419.1389      368.0277  0.0822\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "     99      419.1389      368.0277  0.0804\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    100      419.1389      368.0277  0.0792\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    101      419.1389      368.0277  0.0786\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    102      419.1389      368.0277  0.0786\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    103      419.1389      368.0277  0.0792\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    104      419.1389      368.0277  0.0803\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    105      419.1389      368.0277  0.0795\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    106      419.1389      368.0277  0.0793\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    107      419.1389      368.0277  0.0788\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    108      419.1389      368.0277  0.0787\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    109      419.1389      368.0277  0.0784\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    110      419.1389      368.0277  0.0782\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    111      419.1389      368.0277  0.0782\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    112      419.1389      368.0277  0.0783\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    113      419.1389      368.0277  0.0782\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    114      419.1389      368.0277  0.0785\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    115      419.1389      368.0277  0.0781\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    116      419.1389      368.0277  0.0784\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    117      419.1389      368.0277  0.0785\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    118      419.1389      368.0277  0.0785\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    119      419.1389      368.0277  0.0776\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    120      419.1389      368.0277  0.0780\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    121      419.1389      368.0277  0.0782\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    122      419.1389      368.0277  0.0784\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    123      419.1389      368.0277  0.0782\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    124      419.1389      368.0277  0.0784\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    125      419.1389      368.0277  0.0786\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    126      419.1389      368.0277  0.0787\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    127      419.1389      368.0277  0.0781\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    128      419.1389      368.0277  0.0785\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    129      419.1389      368.0277  0.0779\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    130      419.1389      368.0277  0.0788\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    131      419.1389      368.0277  0.0788\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    132      419.1389      368.0277  0.0784\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    133      419.1389      368.0277  0.0789\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    134      419.1389      368.0277  0.0783\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    135      419.1389      368.0277  0.0790\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    136      419.1389      368.0277  0.0780\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    137      419.1389      368.0277  0.0784\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    138      419.1389      368.0277  0.0780\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    139      419.1389      368.0277  0.0780\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    140      419.1389      368.0277  0.0781\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    141      419.1389      368.0277  0.0790\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    142      419.1389      368.0277  0.0787\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    143      419.1389      368.0277  0.0783\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    144      419.1389      368.0277  0.0786\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    145      419.1389      368.0277  0.0785\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    146      419.1389      368.0277  0.0780\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    147      419.1389      368.0277  0.0783\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    148      419.1389      368.0277  0.0784\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    149      419.1389      368.0277  0.0786\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    150      419.1389      368.0277  0.0787\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    151      419.1389      368.0277  0.0777\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    152      419.1389      368.0277  0.0787\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    153      419.1389      368.0277  0.0784\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    154      419.1389      368.0277  0.0783\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    155      419.1389      368.0277  0.0785\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    156      419.1389      368.0277  0.0784\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    157      419.1389      368.0277  0.0783\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    158      419.1389      368.0277  0.0783\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    159      419.1389      368.0277  0.0788\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    160      419.1389      368.0277  0.0785\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    161      419.1389      368.0277  0.0782\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    162      419.1389      368.0277  0.0780\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    163      419.1389      368.0277  0.0783\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    164      419.1389      368.0277  0.0788\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    165      419.1389      368.0277  0.0785\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    166      419.1389      368.0277  0.0783\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    167      419.1389      368.0277  0.0784\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    168      419.1389      368.0277  0.0788\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    169      419.1389      368.0277  0.0784\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    170      419.1389      368.0277  0.0787\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    171      419.1389      368.0277  0.0786\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    172      419.1389      368.0277  0.0780\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    173      419.1389      368.0277  0.0804\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    174      419.1389      368.0277  0.0812\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    175      419.1389      368.0277  0.0796\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    176      419.1389      368.0277  0.0784\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    177      419.1389      368.0277  0.0784\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    178      419.1389      368.0277  0.0785\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    179      419.1389      368.0277  0.0783\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    180      419.1389      368.0277  0.0786\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    181      419.1389      368.0277  0.0787\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    182      419.1389      368.0277  0.0785\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    183      419.1389      368.0277  0.0780\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    184      419.1389      368.0277  0.0786\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    185      419.1389      368.0277  0.0784\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    186      419.1389      368.0277  0.0789\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    187      419.1389      368.0277  0.0787\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    188      419.1389      368.0277  0.0779\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    189      419.1389      368.0277  0.0784\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    190      419.1389      368.0277  0.0813\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    191      419.1389      368.0277  0.0846\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    192      419.1389      368.0277  0.0841\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    193      419.1389      368.0277  0.0786\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    194      419.1389      368.0277  0.0785\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    195      419.1389      368.0277  0.0783\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    196      419.1389      368.0277  0.0786\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    197      419.1389      368.0277  0.0786\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    198      419.1389      368.0277  0.0788\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    199      419.1389      368.0277  0.0792\n",
      "start\n",
      "torch.Size([120, 61, 2000])\n",
      "torch.Size([120, 122000])\n",
      "start\n",
      "torch.Size([30, 61, 2000])\n",
      "torch.Size([30, 122000])\n",
      "    200      419.1389      368.0277  0.0787\n",
      "start\n",
      "torch.Size([128, 61, 2000])\n",
      "torch.Size([128, 122000])\n",
      "start\n",
      "torch.Size([22, 61, 2000])\n",
      "torch.Size([22, 122000])\n"
     ]
    }
   ],
   "source": [
    "# Only one sample per participant! (Just the 2000 first time points)\n",
    "\n",
    "from skorch import NeuralNetRegressor\n",
    "\n",
    "X = data_raw_train[:,:,:2000]\n",
    "y = labels_raw_train\n",
    "\n",
    "net = NeuralNetRegressor(\n",
    "    SimpleNN,\n",
    "    max_epochs=200,\n",
    "    lr=0.1,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "net.fit(X,y)\n",
    "y_proba = net.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/skorch-dev/skorch?tab=readme-ov-file\n",
    "# deactivate skorch-internal train-valid split and verbose logging\n",
    "model.set_params(train_split=False, verbose=0)\n",
    "params = {\n",
    "    'lr': [0.01, 0.02],\n",
    "    'max_epochs': [10, 20],\n",
    "    'module__num_units': [10, 20],\n",
    "}\n",
    "gs = GridSearchCV(model, params, refit=False, cv=3, scoring='accuracy', verbose=2)\n",
    "\n",
    "gs.fit(X, y)\n",
    "print(\"best score: {:.3f}, best params: {}\".format(gs.best_score_, gs.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'perform_cross_validation2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m h_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m batch_size\n\u001b[1;32m     23\u001b[0m h_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m number_samples\n\u001b[0;32m---> 25\u001b[0m \u001b[43mperform_cross_validation2\u001b[49m(train_dataset[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m5\u001b[39m, h_params, unique_identifier)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# perform_cross_validation_on_the_simple_fcn(full_train_dataset, 5, h_params, unique_identifier)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'perform_cross_validation2' is not defined"
     ]
    }
   ],
   "source": [
    "LR = [0.001]#, 0.0005, 0.002]\n",
    "BATCH_SIZES = [1] #, 4, 16, 32, 64]\n",
    "\n",
    "NUMBER_SAMPLES = [1]#, 4, 16, None]\n",
    "\n",
    "# Next attempt: SimpleNN\n",
    "for lr in LR: \n",
    "    for batch_size in BATCH_SIZES: \n",
    "        for number_samples in NUMBER_SAMPLES: \n",
    "            now = datetime.now()\n",
    "            # unique_identifier = f\"EEG_shallowFBCSPNet_-{now.strftime('%Y_%m_%d-%H_%M')}\" #(\"%Y%m%d_%H%M%S\")\n",
    "            unique_identifier = f\"Simple_NN-{now.strftime('%Y_%m_%d-%H_%M')}\" #(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "            model = model.to(device)\n",
    "            print(\"datasets\")\n",
    "            print(train_dataset[0][1].shape)\n",
    "\n",
    "            # full_train_dataset = torch.utils.data.ConcatDataset([train_dataset, val_dataset])\n",
    "            # print(full_train_dataset[0][0].shape) #x \n",
    "            # I AM UNSURE IF THIS WORKS - so I replaced it for now with only the training set. \n",
    "            h_params[\"lr\"] = lr\n",
    "            h_params[\"batch_size\"] = batch_size\n",
    "            h_params[\"number_samples\"] = number_samples\n",
    "\n",
    "            perform_cross_validation2(train_dataset[0], 5, h_params, unique_identifier)\n",
    "            # perform_cross_validation_on_the_simple_fcn(full_train_dataset, 5, h_params, unique_identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WORKS\n",
    "now = datetime.now()\n",
    "# unique_identifier = f\"EEG_shallowFBCSPNet_-{now.strftime(\"%Y_%m_%d-%H_%M\")}\" #(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# model = model.to(device)\n",
    "\n",
    "# full_train_dataset = torch.utils.data.ConcatDataset([train_dataset, val_dataset])\n",
    "\n",
    "# perform_cross_validation(full_train_dataset, 5, h_params, unique_identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/EEG_shallowFBCSPNet_Adam-2024_03_08-01_28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Validation Loss: 23.7685\n",
      "Epoch [2/50], Validation Loss: 23.7464\n",
      "Epoch [3/50], Validation Loss: 23.7250\n",
      "Epoch [4/50], Validation Loss: 23.7179\n",
      "Epoch [5/50], Validation Loss: 23.7137\n",
      "Epoch [6/50], Validation Loss: 23.7082\n",
      "Epoch [7/50], Validation Loss: 23.6957\n",
      "Epoch [8/50], Validation Loss: 23.6604\n",
      "Epoch [9/50], Validation Loss: 23.6078\n",
      "Epoch [10/50], Validation Loss: 23.5330\n",
      "Epoch [11/50], Validation Loss: 23.4387\n",
      "Epoch [12/50], Validation Loss: 23.3394\n",
      "Epoch [13/50], Validation Loss: 23.2524\n",
      "Epoch [14/50], Validation Loss: 23.1239\n",
      "Epoch [15/50], Validation Loss: 22.9867\n",
      "Epoch [16/50], Validation Loss: 22.7739\n",
      "Epoch [17/50], Validation Loss: 22.4569\n",
      "Epoch [18/50], Validation Loss: 21.8786\n",
      "Epoch [19/50], Validation Loss: 20.9543\n",
      "Epoch [20/50], Validation Loss: 19.7718\n",
      "Epoch [21/50], Validation Loss: 18.4017\n",
      "Epoch [22/50], Validation Loss: 17.2036\n",
      "Epoch [23/50], Validation Loss: 16.6899\n",
      "Epoch [24/50], Validation Loss: 16.0767\n",
      "Epoch [25/50], Validation Loss: 15.4445\n",
      "Epoch [26/50], Validation Loss: 14.5909\n",
      "Epoch [27/50], Validation Loss: 13.5167\n",
      "Epoch [28/50], Validation Loss: 12.3128\n",
      "Epoch [29/50], Validation Loss: 11.0030\n",
      "Epoch [30/50], Validation Loss: 9.6819\n",
      "Epoch [31/50], Validation Loss: 8.7508\n",
      "Epoch [32/50], Validation Loss: 7.6206\n",
      "Epoch [33/50], Validation Loss: 6.8775\n",
      "Epoch [34/50], Validation Loss: 6.0504\n",
      "Epoch [35/50], Validation Loss: 5.1812\n",
      "Epoch [36/50], Validation Loss: 4.4752\n",
      "Epoch [37/50], Validation Loss: 3.7319\n",
      "Epoch [38/50], Validation Loss: 3.0043\n",
      "Epoch [39/50], Validation Loss: 2.4065\n",
      "Epoch [40/50], Validation Loss: 2.1714\n",
      "Epoch [41/50], Validation Loss: 2.2078\n",
      "Epoch [42/50], Validation Loss: 2.1956\n",
      "Epoch [43/50], Validation Loss: 2.1711\n",
      "Epoch [44/50], Validation Loss: 2.2337\n",
      "Epoch [45/50], Validation Loss: 2.3090\n",
      "Epoch [46/50], Validation Loss: 2.2705\n",
      "Epoch [47/50], Validation Loss: 2.2136\n",
      "Epoch [48/50], Validation Loss: 2.1836\n",
      "Epoch [49/50], Validation Loss: 2.1738\n",
      "Epoch [50/50], Validation Loss: 2.2541\n"
     ]
    }
   ],
   "source": [
    "# # Unique Identifier to encode day and time\n",
    "# now = datetime.now()\n",
    "# unique_identifier = now.strftime(\"%Y_%m_%d-%H_%M\") #(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# writer_name = f'logs/EEG_shallowFBCSPNet_Adam-{unique_identifier}'\n",
    "# writer = SummaryWriter(writer_name)\n",
    "# print(writer_name)\n",
    "\n",
    "# writer.add_hparams(h_params, {})\n",
    "\n",
    "\n",
    "# # Initializing the list for storing the loss \n",
    "# train_loss_history = [] # loss\n",
    "\n",
    "# model = model.to(device)\n",
    "\n",
    "# for epoch in range(h_params[\"num_epochs\"]):\n",
    "#     model.train() \n",
    "#     running_loss = 0.0\n",
    "\n",
    "#     for i, (X, y) in enumerate(train_loader): \n",
    "\n",
    "#         X, y = X.to(device), y.to(device)\n",
    "#         y = y.unsqueeze(-1)  \n",
    "\n",
    "#         optimizer.zero_grad() \n",
    "\n",
    "#         outputs = model(X) \n",
    "#         loss = criterion(outputs, y)\n",
    "\n",
    "#         loss.backward()  \n",
    "#         optimizer.step()  \n",
    "\n",
    "#         running_loss += loss.item()\n",
    "#         loss_in_years = torch.sqrt(loss)\n",
    "#         writer.add_scalar('Loss_in_years/train', loss_in_years.item(), epoch * len(val_loader) + i)\n",
    "#         # writer.add_hparams(h_params, {'hparam/loss_train_in_y':loss_in_years.item()}) #, 'hparam/loss_val_in_y': np.sqrt(avg_val_loss)})\n",
    "\n",
    "#         # Print statistics to console\n",
    "#         frequency_of_updates = 4\n",
    "#         if i % frequency_of_updates == frequency_of_updates - 1:\n",
    "#             current_loss = np.sqrt(running_loss / frequency_of_updates)\n",
    "#             print(f\"[Epoch {epoch+1}, Iteration {i+1}] loss: {current_loss:.3f}\")\n",
    "#             train_loss_history.append(current_loss)\n",
    "#             running_loss = 0.0\n",
    "\n",
    "\n",
    "\n",
    "#     # Validation phase\n",
    "#     model.eval()\n",
    "#     val_running_loss = 0.0\n",
    "#     val_total = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for i, (X, y) in enumerate(val_loader):\n",
    "#             X, y = X.to(device), y.to(device)\n",
    "#             y = y.unsqueeze(1)  # Ensure y is the correct shape for comparison\n",
    "\n",
    "#             outputs = model(X)\n",
    "#             val_loss = criterion(outputs, y)\n",
    "\n",
    "#             val_running_loss += val_loss.item()\n",
    "#             val_total += y.size(0)\n",
    "\n",
    "#     avg_val_loss = val_running_loss / len(val_loader)\n",
    "#     writer.add_scalar('Loss/val', np.sqrt(avg_val_loss), epoch)\n",
    "#     # writer.add_hparams(h_params, {'hparam/loss_val_in_y': np.sqrt(avg_val_loss)})\n",
    "\n",
    "\n",
    "#     print(f'Epoch [{epoch+1}/{h_params[\"num_epochs\"]}], Validation Loss: {np.sqrt(avg_val_loss):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good Graphs of Samples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot of one person and one sample over all \n",
    "# ages = []\n",
    "\n",
    "# # Get one batch \n",
    "# for j, data_train in enumerate(train_loader, 0): \n",
    "#     print(j)\n",
    "#     print(f\"train_loader sample {j} is {len(data_train)}, {len(data_train[0])}, {len(data_train[0][0])}, {len(data_train[0][0][0])} big.\")\n",
    "#     # x,y; people, channels; timesteps\n",
    "\n",
    "\n",
    "#     # Iterate through all people of one batch \n",
    "#     for data_of_one_sample, age in zip(data_train[0], data_train[1]): # x of people, y of people\n",
    "#         plt.plot(data_of_one_sample.T)\n",
    "#         ages.append(age)\n",
    "#         plt.title(f\"Data of one sample of a {age[0]} year old participant\")\n",
    "#         plt.show()\n",
    "#     # plt.plot(data_train[j][0][i])\n",
    "\n",
    "#     break\n",
    "\n",
    "# ages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# means = []\n",
    "# y_values = []\n",
    "\n",
    "# for i, data in enumerate(train_loader, 0):\n",
    "\n",
    "#     print(data[0].shape) #[0])\n",
    "#     # Compute the mean of each datapoint (assuming inputs are tensors of shape [batch_size, 61, 2000])\n",
    "\n",
    "#     mean = data[0].mean(dim=[1, 2])  # This computes the mean across both dimensions for each item in the batch\n",
    "#     means.extend(mean.tolist())  # Convert to list and store\n",
    "#     y_values.extend(data[1].flatten().tolist())  # Flatten labels and store\n",
    "\n",
    "# # Now plot the means vs. y-values\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(means, y_values)\n",
    "# plt.title('Mean of Each Measurement vs. Age')\n",
    "# plt.xlabel('Mean of All EEG Measurementpoints')\n",
    "# plt.ylabel('Age')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 2000962564 bytes\n",
      "Model size: 1908.2666053771973 MiB\n"
     ]
    }
   ],
   "source": [
    "# # Get number of parameters\n",
    "# # def count_parameters(model):\n",
    "# #     return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# # Determine size in bytes of model \n",
    "# def model_size_in_bytes(model):\n",
    "#     param_size = 0\n",
    "#     for param in model.parameters():\n",
    "#         param_size += param.nelement() * param.element_size()\n",
    "#     size_in_bytes = param_size  # Only parameters, no gradients or activations\n",
    "#     return size_in_bytes\n",
    "\n",
    "# # model_parameters = count_parameters(model)\n",
    "# # print(f\"Number of trainable parameters: {model_parameters}\")\n",
    "\n",
    "# model_size_bytes = model_size_in_bytes(model)\n",
    "# model_size_mibs = model_size_bytes / (1024 ** 2)  # Convert bytes to MiB\n",
    "\n",
    "# print(f\"Model size: {model_size_bytes} bytes\")\n",
    "# print(f\"Model size: {model_size_mibs} MiB\")\n",
    "\n",
    "\n",
    "# # Goal: Have the GPU Memory be at least 3/4 times as large (GPU has 16384 MiB >> max 4096 to 5461). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mae3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
